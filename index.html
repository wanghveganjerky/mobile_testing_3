<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
    <title>microsites</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <!-- <link rel="stylesheet" href="https://use.typekit.net/ofl8mwn.css"> -->
  </head>
  <body>
    <div id="box1">
      <img id="logo" src="images/5.jpg">
    </div>
    <div id="box2">
      <h1>"anything that can be automated, will be automated."</h1>
      <p>Engineers and architects possess skills most others lack — skills that allow them to transform dreams of design into reality... But these same technical gifts alone, in the absence of a sense of morality and a capacity for critical thought and judgment, can also make reality of nightmares.The companies building generative models like to claim that they are democratizing creativity and giving artistic “superpowers” to the apparently semi-literate and maladroit masses — much as TikTok’s suite of tools “democratizes” content creation on its platform and allows otherwise boring people to seemingly keep pace with influencers and celebrities.

        But the easier the tools are to use, or the more powerful the generative models are, the more they may convert people into no more than their users and consumers. They train us to enjoy not having intentionality or enjoying “intentionality” as an abstraction, as just flipping channels randomly to see what’s on or feeding language to a machine just to see what it can be made to spit out.
      When tinkerers and hobbyists, doodlers and scribblers—not to mention kids just starting to perceive and explore the world—have this kind of instant gratification at their disposal, their curiosity is hijacked and extracted. For all the surrealism of these tools’ outputs, there’s a banal uniformity to the results. When people’s imaginative energy is replaced by the drop-down menu “creativity” of big tech platforms, on a mass scale, we are facing a particularly dire form of immiseration.</p>
    </div>
    <div id="box3">
      <p>Why bother asking users how they feel about a design if ultimately you just ship what moves the needle?</p>
    </div>
      <div id="box4">
        <p>How many of us would be willing to compartmentalize our emotions, suppress our consciences, almost to sell our souls, for the opportunity to work on the grand projects that Speer was involved in? How many of us are so focused on solving a technical problem that we fail to contemplate where that solution might lead?</p>
      </div>
      <div id="box5">
       <p>[Albert Speer] convinced himself of what remains one of the shibboleths of the technical professions to this day: that science and technology, no matter what their implications or the ends toward which they are employed, are completely apolitical and amoral in character.

        This is a fiction we must devote ourselves to breaking — in our culture at large, but starting with the education of the practitioners of the technological and scientific enterprise.
        "The low-costs associated with sending media to many, also inversely deteriorates the value of it for the receiver. The audience becomes wider and the shared content slowly changes from vulnerable selfies to more polished pictures of food, or views of buildings and beaches. When you pick a person first instead, and then capture something for them, it’s completely the other way around. For the receiver, the message is more meaningful — since they’re assured the message is created exclusively for them." (Onno Faber)</p>
      </div>
      <div id="box6">
        <img src="images/1.jpg">
      </div>
      <div id="box7">
        <h1>Ted Nelson</h1>
    <p>The internet is an information landfill. Somewhere in it—buried under piles of opinion, speculation, and misinformation—is virtually all of human knowledge. But sorting through the trash is difficult work. Even when you have something you think is valuable, it often turns out to be a cheap knock-off.</p>
      </div>
      <div id="box8">
        <p>We have been so desensitized by a hundred and fifty years of ceaselessly expanding technical prowess that we think nothing less complex and showy than a computer or a jet bomber deserves to be called "technology " at all. As if linen were the same thing as flax — as if paper, ink, wheels, knives, clocks, chairs, aspirin pills, were natural objects, born with us like our teeth and fingers -- as if steel saucepans with copper bottoms and fleece vests spun from recycled glass grew on trees, and we just picked them when they were ripe...
          One way to illustrate that most technologies are, in fact, pretty "hi," is to ask yourself of any manmade object, Do I know how to make one?
          Anybody who ever lighted a fire without matches has probably gained some proper respect for "low" or "primitive" or "simple" technologies; anybody who ever lighted a fire with matches should have the wits to respect that notable hi-tech invention.
          I don't know how to build and power a refrigerator, or program a computer, but I don't know how to make a fishhook or a pair of shoes, either. I could learn. We all can learn. That's the neat thing about technologies. They're what we can learn to do.</p> </div>
    
    <div id="box9">
      
      <p>Ethical and moral values and questions are often treated as clearly separable (and separate) from ‘‘scientific work’’ and as some- thing with which the scientist need not contaminate their ‘‘objective’’ work.

        In its desire for absolute rationality, Western thought wishes to cleave thought from emotion, cultural influence, and ethical dimensions.
        
        Abstract and intellectual thinking are regarded as the most trustworthy forms of understanding, and rationality is fetishized. Data science, and the wider discipline of computer science, have implicitly or explicitly inherited this worldview.</p>
    </div>
    <div id="box10">
      <img src="images/2.jpg">
    </div>
    <div id="box11">
      <p>Our choice is not between "regulation" and "no regulation." The code regulates. It implements values, or not. It enables freedoms, or disables them. It protects privacy, or promotes monitoring. People choose how the code does these things. People write the code. Thus the choice is not whether people will decide how cyberspace regulates. People--coders--will. The only choice is whether we collectively will have a role in their choice--and thus in determining how these values regulate--or whether collectively we will allow the coders to select our values for us.</p>
    </div>
    <div id="box12"><p>. . . Color, of course, is deeply connected to light. What is also happening in the last twenty years or so is that the digital colors have become more intense and, in parallel, the colors of our actual environment are becoming more neutral. The fact that digital color and any kind of digital rendering is presented on a screen means that you look at those colors, whatever they are—even black, white and grays—with light behind them. That in itself gives an added intensity or attraction. Reality is by definition flat in comparison to the experience of seeing colors on a screen. There is an almost disappointing dimension to reality.</p></div>
    <div id="box13">
      <p>“Computer simulation” is not something on a screen but a matter of how “the real world” itself comes to be seen — as no more than code, made up of information rather than matter (or matter that is understood as no more than encoded information). This mirrors the generative AI premise that data about the world is in itself sufficient to understand and reproduce it.</p>
      
    </div>
    <div id="box14">
      <img src="images/3.jpg">
    </div>
    <div id="box15">
      <img src="images/4.jpg">
      
    </div>
    <div id="box16">
      
        <h1>Maybe it’s time we reintroduce friction in the browsing experience.</h1>
    <p>	When tinkerers and hobbyists, doodlers and scribblers—not to mention kids just starting to perceive and explore the world—have this kind of instant gratification at their disposal, their curiosity is hijacked and extracted. For all the surrealism of these tools’ outputs, there’s a banal uniformity to the results. When people’s imaginative energy is replaced by the drop-down menu “creativity” of big tech platforms, on a mass scale, we are facing a particularly dire form of immiseration.</p>
    </div>
    <div id="box17">
      <p>“Document the moments you feel most in love with yourself - what you’re wearing, who you’re around, what you’re doing. Recreate and repeat.” ― Warsan Shire

        What is the difference between documenting for others and documenting for yourself? On social media we're essentially documenting moments of love, when we think we look good, and creating some infinite feedback loop of trying to always look good. What would a different kind of documentation look like- one where aiming for moments of love was productive rather than performative?</p>
    </div>
    <div id="box18">
      <p>By making Sharing a tap or two away, have we also diluted the gravity of that action? Sharing something in the real world in front of a group of people demands conviction and bravery; we share when we believe in what we have to say so much that we are willing to risk potential humiliation and ridicule.</p>
    </div>
    <div id="box19">
    <img src="images/4.jpg">
    </div>
    </body>
  <script src="main.js"></script>
</html>
